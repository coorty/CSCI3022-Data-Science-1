{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 13: The Central Limit Theorem\n",
    "***\n",
    "\n",
    "We'll need Numpy, Matplotlib, Pandas, and scipy.stats for this notebook, so let's load them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from scipy import stats\n",
    "import matplotlib.pylab as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - Estimating Mean Income from a Population\n",
    "*** \n",
    "\n",
    "The file income_data.csv contains Age and Income information from a fictitious city in the Midwest with 5000 residents.  \n",
    "\n",
    "**Part A**: Shift-Enter the following cells to load the data into a pandas DataFrame called dfIncome and make a histogram of the data with <S-CR>0 bins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"data/income_data.csv\"\n",
    "web_path   = \"https://raw.githubusercontent.com/chrisketelsen/csci3022/master/inclass-notebooks/data/income_data.csv\"\n",
    "file_path  = web_path \n",
    "\n",
    "dfIncome = pd.read_csv(file_path)\n",
    "dfIncome.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,6))\n",
    "dfIncome.hist(column=\"Income\", bins=20, color=\"steelblue\", edgecolor=\"white\", ax=ax)\n",
    "ax.grid(alpha=0.25)\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_title(\"Income Data from Entire Population\", fontsize=16)\n",
    "ax.set_xlabel(\"Income\", fontsize=16)\n",
    "ax.set_ylabel(\"Frequency\", fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: How would you characterize the distribution of Income in the population? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Determine the mean-income for the entire population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: In real life, we have populations much bigger than $5000$.  If we want to estimate the mean of the population we have to draw a sample from the population and compute the sample mean.  The important questions we have to ask are things like: \n",
    "\n",
    "- Is the sample mean a good approximation of the population mean? \n",
    "- How large does my sample need to be in order for the sample mean to well-approximate the population mean? \n",
    "\n",
    "Complete the following function to [sample](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html) $n$ rows from dfIncome and return the estimated mean. Start with a sample size of 10 and draw at least 5 estimated means from your function.  Are the estimated means good approximations to the population mean we computed above? What if you increase the sample size?  Discuss the results with your neighbors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def income_sample_mean(df, n):\n",
    "    return 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: Notice, that for a sample-size of $n$, our function is returning an estimator of the form \n",
    "\n",
    "$$\n",
    "\\bar{X} = \\frac{1}{n}\\sum_{k=1}^n X_k \n",
    "$$\n",
    "\n",
    "If we think of each $X_k$ as being an independent and identically distributed (i.i.d.) random variable that follows the population distribution, what can you say about the estimated mean $\\bar{X}$? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**: If $\\bar{X}$ is a random variable then it too must have a distribution. We call the distribution of $\\bar{X}$ the **sample distribution**.  But what the heck does this distribution look like? \n",
    "\n",
    "Let's explore. \n",
    "\n",
    "One way that we could do this is to sample from the sample distribution by computing many **independent estimates** of the population mean and draw a histogram.  Complete the function income_sample_dist to draw at least 1000 estimates of the mean with a given sample size $n$ and then draw a histogram of the results. Start with a sample size of $n=5$ and then increase it to $n=50$, $n=500$, etc. Discuss your results with your neighbors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def income_sample_dist(df, n=5, num_means=1000):\n",
    "    means = #TODO \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 - Estimating Means of the Binomial Distributions\n",
    "*** \n",
    "\n",
    "The size of the sample that you have to draw before the estimator becomes approximately normally distributed depends on how non-normal the population distribution is.  In this exercise we'll look at the sample means of the Binomial distribution when $p=0.5$ (pretty normal) and $p=0.95$ (pretty non-normal). \n",
    "\n",
    "**Part A**: Draw at least $10000$ samples from the distribution $Bin(6,0.5)$ and $Bin(6,0.95)$ and make histograms with compatible axes-limits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: We know from class that the expected value of $Bin(n,p)$ is $E[X] = np$.  Complete the function est_mean_bin below to draw estimates of the mean of $Bin(n,p)$ of a given sample size. Test your function by drawing several means with a sample size of your choice.  Do you get results that are fairly close to $E[X]$ for your given choice of parameter? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def est_mean_bin(n=6, p=0.5, sample_size=5):\n",
    "    return 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Complete the function sample_bin_dist that computes many independent estimates of the mean of $Bin(n,p)$ and plots their histogram.  Vary the size of the samples in each estimate.  How big does the sample size have to be for $Bin(6,0.5)$ before the sample distribution looks approximately normal? How big does the sample size have to be for $Bin(6,0.95)$ before the sample distribution looks approximately normal? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_bin_dist(n=6, p=0.5, sample_size=5, num_means=int(5e4)):\n",
    "    means = #TODO \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 - The CLT and Monte Carlo Simulation \n",
    "*** \n",
    "\n",
    "In this exercise we'll see how we can use the CLT to estimate how good our approximation from a simulation actually is. \n",
    "\n",
    "**Part A**: Let $X$ be a random variable taking on the face values of a $d$-sided die after a single roll.  If the die is fair, then $X$ follows a discrete uniform distribution of the form $\\textrm{unif}\\{1,d\\}$. Look up the mean and variance of $\\textrm{unif}\\{1,d\\}$ on [wiki](https://en.wikipedia.org/wiki/Discrete_uniform_distribution) and figure out the specific values of the mean and variance when $d=6$.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Write a function sim_die that takes as arguments integers $d$ representing the number of sides on the die and $n$ representing the number of iterations to run your simulation.  The function should return an estimate of the expected value of the die roll, as well as an array of the results of each of the $n$ rolls in the simulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sim_die(d=6, n=int(1e3)):\n",
    "    rolls = #TODO \n",
    "    return np.mean(rolls), rolls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Write a function running_est that takes in your rolls history from **Part B** and computes the running estimate of the expected value after each new sample in the simulation.  That is, your function should return an array $r$ such that \n",
    "\n",
    "$$\n",
    "r[i] = \\frac{\\textrm{Estimate after i samples}}{i} \\quad \\textrm{for }i=1,2,\\ldots,n\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def running_est(rolls):\n",
    "    return np.ones(len(rolls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Let $\\bar{X}_n$ the the random variable that estimates $E[X]$ using the first $n$ rolls of the simulation.  Based on the Central Limit Theorem, what distribution does the $\\bar{X}_n$ follow when $d=6$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: Give an upper and lower bound for a region that $\\bar{X}_n$ will fall in with 95% probability when $d=6$ as a function of $n$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**: The following function takes the number of sides of the dice and your array of running estimates of the mean and plots the trajectory of the running estimate.  If you set the bounds flag to True it plots a shaded region enclosing the mean.  Currently the shaded region is a constant interval.  Your job in this part of the exercise is to modify the array err95 so that the shaded region depicts the 95% confidence interval around the mean of the estimator. \n",
    "\n",
    "**Note**: For bonus (non-existent) points, make your implementation general with respect to the number of sides on the dice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def running_plot(d, r, bounds=False):\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,5))\n",
    "    ax.plot(range(1,len(r)+1),r, color=\"steelblue\")\n",
    "    ax.grid(alpha=0.25)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.set_ylim([np.mean(range(1,d+1))-1.5, np.mean(range(1,d+1))+1.5])\n",
    "    ax.set_xlim([1,len(r)])\n",
    "    ax.set_xlabel(\"iteration\", fontsize=16)\n",
    "    ax.set_ylabel(\"estimate\", fontsize=16)\n",
    "    \n",
    "    mu = 3.5\n",
    "    var = np.nan\n",
    "    sd = np.nan \n",
    "    \n",
    "    if bounds: \n",
    "        err95 = np.ones(len(r))\n",
    "        ax.fill_between(range(1,len(r)+1), mu+err95, mu-err95, color=\"steelblue\", alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=6\n",
    "x, rolls = sim_die(d=d, n=int(1e3))    \n",
    "r = running_est(rolls)\n",
    "running_plot(d,r,bounds=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part G**: If you run your simulation enough times, you'll eventually get a case where the running estimate wanders outside of the shaded region.  How can you explain this? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**: If you didn't make your bounds estimate general in **Part F**, go back and do so now.  Then run the experiment for dice with increasing number of sides.  What differences do you notice in the trajectory and confidence interval?  How can you explain the differences? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
