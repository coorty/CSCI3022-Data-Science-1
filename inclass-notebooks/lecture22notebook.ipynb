{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 22: Multiple Linear Regression\n",
    "***\n",
    "\n",
    "We'll need Numpy, Matplotlib, Pandas, and scipy.stats for this notebook, so let's load them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - Advertising Budgets and Simple Linear Regression\n",
    "*** \n",
    "\n",
    "The data in advertising.csv concerns the sales of a particular product in 200 different markets, along with advertising budgets for each market for three different media types: TV, Radio, and Newspaper.  The sales feature is given in thousands of units, and each of the advertising budget features are given in thousands of dollars.\n",
    "\n",
    "\n",
    "**Part A**: Load the data into a Pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAd = pd.read_csv(\"data/advertising.csv\")\n",
    "dfAd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Run the following code to make three separate scatter plots depicting the relationships between each of the features, $\\texttt{TV}$, $\\texttt{radio}$, and $\\texttt{news}$ on the response variable $\\texttt{sales}$. From the plots, can you determine whether there appears to be a relationship between each of the advertising media types and the sales of the product? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media = [\"tv\", \"radio\", \"news\"]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(8,16))\n",
    "axes[0].scatter(dfAd[\"tv\"], dfAd[\"sales\"])\n",
    "\n",
    "for axi, m in enumerate(media): \n",
    "    axes[axi].scatter(dfAd[m], dfAd[\"sales\"], color=\"steelblue\")\n",
    "    axes[axi].grid(alpha=0.25)\n",
    "    axes[axi].set_xlabel(m, fontsize=16)\n",
    "    axes[axi].set_ylabel(\"sales\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Use [stats.linregress](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.linregress.html) to fit three simple linear regression models to the data of the form \n",
    "\n",
    "$$\n",
    "Y_i = \\alpha + \\beta x_i + \\epsilon_i, \\quad \\textrm{for } i=1,2, \\ldots, n\n",
    "$$\n",
    "\n",
    "where $x$ is a particular media type and  $\\epsilon \\sim N(0,\\sigma^2)$. Interpret your results.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media = [\"tv\", \"radio\", \"news\"]\n",
    "\n",
    "for m in media: \n",
    "    print(\"SLR for {} vs sales\".format(m))\n",
    "    print(\"----------------------\")\n",
    "    bhat, ahat, rval, pval, stderr = # TODO \n",
    "    print(\"intercept = {:.4f}\".format(ahat))\n",
    "    print(\"slope = {:.4f}\".format(bhat))\n",
    "    print(\"p-value = {}\".format(pval))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 - Advertising Budgets and Multiple Linear Regression\n",
    "*** \n",
    "\n",
    "In this exercise you'll fit a multiple linear regression model to the advertising data.  For this we'll need a package that we haven't encountered yet called [statsmodels](http://www.statsmodels.org/stable/index.html).  We load it as follows.  Note that you might get a FutureWarning from Pandas.  This is expected. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: The following code will fit an MLR model to the data. Note that the add_constant function is necessary in order to include an intercept term in the MLR model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Collect the features in a 2D array \n",
    "X = dfAd[[\"tv\", \"radio\", \"news\"]]\n",
    "\n",
    "# Add a constant to the array for the intecept \n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Collect the response data in an array \n",
    "y = dfAd[\"sales\"]\n",
    "\n",
    "# Fit the ordinary least-squares (OLS) model \n",
    "model = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated parameters are for the model are stored in model.params.  In this case, because we got $X$ from a Pandas DataFrame, the resulting model parameters are stored in a Pandas Series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Based on the parameters estimated by the model, replace the unknown $\\hat{\\beta}_j$ parameters below with the actual values in the model \n",
    "\n",
    "$$\n",
    "\\texttt{sales} = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\times \\texttt{TV} + \\hat{\\beta}_2 \\times \\texttt{radio} + \\hat{\\beta}_3 \\times \\texttt{news}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Compare and contrast the model parameters obtained from multiple linear regression with those obtained from the individual simple linear regression models obtained in Exercise 1.  Does something seem fishy? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: We can compute the pair-wise correlation between each of the features directly from the DataFrame using Pandas .corr() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAd[[\"tv\", \"radio\", \"news\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does any pair of features seem particularly correlated?  Can you use this to explain the fishiness observed in **Part D**? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 - Polynomial Regression via Multiple Linear Regression \n",
    "*** \n",
    "\n",
    "It's not too difficult to believe that some relationships between features and the response are nonlinear. Consider the following example, where the single feature $x$ and the response $y$ have a quadratic relationship of the form \n",
    "\n",
    "$$\n",
    "Y = \\frac{1}{4} - X + X^2 + \\epsilon \n",
    "$$\n",
    "\n",
    "The following code samples $n=30$ data points from the true model, fits the SLR model, and plots it against the data. It should be clear from both the picture and the $R^2$-value that the SLR model is a very poor fit of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data\n",
    "n, sig = 30, 0.05\n",
    "x = np.linspace(0,1,n) + 0.05*np.random.rand(n) \n",
    "y = 0.25 - x + x**2 + stats.norm.rvs(0,sig,size=n)\n",
    "\n",
    "# Fit SLR model \n",
    "bhat, ahat, rval, pval, stderr = stats.linregress(x, y)\n",
    "\n",
    "# Plot data and SLR model \n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,6))\n",
    "xplot = np.linspace(np.min(x), np.max(x))\n",
    "ax.plot(xplot, ahat + bhat*xplot, color=\"steelblue\", lw=3)\n",
    "ax.scatter(x, y, color=\"steelblue\", s=100, alpha=0.9)\n",
    "ax.grid(alpha=0.25)\n",
    "ax.set_xlabel(\"X\", fontsize=16)\n",
    "ax.set_ylabel(\"Y\", fontsize=16)\n",
    "ax.text(0.8, np.min(y)+.00, r\"$R^2$={:.3f}\".format(rval**2), fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: We can fit a **polynomial** model to the single-feature data be thinking of the polynomial features as features in a multiple linear regression model.  If we make the association  \n",
    "\n",
    "$$\n",
    "x_1 = x \\quad \\textrm{and} \\quad x_2 = x^2 \n",
    "$$\n",
    "\n",
    "then we can fit a multiple linear regression of the form \n",
    "\n",
    "$$\n",
    "\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\hat{\\beta}_2 x_2 \n",
    "$$\n",
    "\n",
    "Let's see how we can do this in python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the linear feature x and it's square in an array \n",
    "X = np.column_stack((x, x**2))\n",
    "\n",
    "# Add a constant to the array for the intecept \n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the ordinary least-squares (OLS) model \n",
    "polymodel = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print estimated parameters \n",
    "print(polymodel.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Write down the estimated MLR model in terms of the features $x_1$ and $x_2$ as well as the interpretation of the associated polynomial model in terms of the single feature $x$. Does this model seem close to the true model that the data was generated from?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Modify the code below to plot the obtained polynomial regression model against the data.  How does it look?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data and SLR model \n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,6))\n",
    "xplot = np.linspace(np.min(x), np.max(x))\n",
    "yplot = #TODO \n",
    "ax.plot(xplot, yplot, color=\"steelblue\", lw=3)\n",
    "ax.scatter(x, y, color=\"steelblue\", s=100, alpha=0.9)\n",
    "ax.grid(alpha=0.25)\n",
    "ax.set_xlabel(\"X\", fontsize=16)\n",
    "ax.set_ylabel(\"Y\", fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 - Guessing Polynomial Features from Residual Plots \n",
    "*** \n",
    "\n",
    "In the previous exercise we looked for a polynomial regression model that was quadratic because we already knew the true form of the model (which never happens in practice).  If we don't know how many polynomial features to include in our regression model, we can gain insight into which features might be missing by plotting the associated residuals.  Recall that the residual is the difference between the true response value $y$ and the response predicted by the model, $\\hat{y}$: \n",
    "\n",
    "$$\n",
    "r_i = y_i - \\hat{y}_i \n",
    "$$\n",
    "\n",
    "**Part A**: Suppose that your data really is linear.  What do you expect a scatter plot of the residuals to look like? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Before continuing, scroll down and execute the cell in the **Helper Functions** section at the bottom of this notebook. \n",
    "\n",
    "**Part B**: The following code samples data from a true linear model, fits a SLR model to it, and plots the model and the associated residuals.  Does the residual plot agree with what you concluded in **Part A**? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = nonlinear_data(dataset=0)\n",
    "fit_and_res_plot(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Now consider a data set that is not linear.  What do you notice about the associated residual plot? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = nonlinear_data(dataset=1)\n",
    "fit_and_res_plot(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: What polynomial feature do you think is missing?  Complete the following code be adding the missing feature and running the fit again.  What does the residual plot look like now? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = nonlinear_data(dataset=1)\n",
    "X = np.column_stack((X, # TODO \n",
    "fit_and_res_plot(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: OK, one more dataset.  See if you can figure out the missing features and obtain a polynomial regression model that fits the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = nonlinear_data(dataset=2)\n",
    "fit_and_res_plot(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "\n",
    "### Helper Functions\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nonlinear_data(dataset, n=30):\n",
    "    \n",
    "    if dataset < 0 or dataset > 2: \n",
    "        print(\"Datasets must be numbered 0-2.  Defaulting to 0.\")\n",
    "        dataset = 0\n",
    "    \n",
    "    np.random.seed(1237)\n",
    "    \n",
    "    X = np.linspace(0,1,n) + .05 * np.random.rand(n)\n",
    "    \n",
    "    if dataset == 0: \n",
    "       return  X, 0.5 + 0.75 * X + .5*np.random.rand(n)\n",
    "    elif dataset == 1: \n",
    "       return  X, 0.25 - X + X*X + .1*np.random.rand(n)\n",
    "    elif dataset == 2: \n",
    "       return  X, 2*(3*(2*x-1.2)**3 + 2*(2*x-1.2)**2 -(2*x-1.2)) + 1.5*np.random.rand(n)\n",
    "\n",
    "def fit_and_res_plot(X, y, hint=False):\n",
    "    \n",
    "    if len(X.shape)==1:\n",
    "        x = X\n",
    "    else:\n",
    "        x = X[:,0]\n",
    "    \n",
    "    # Fit Data \n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X).fit() \n",
    "    \n",
    "    # Print fitted model \n",
    "    print(\"Fitted PLR Model: yhat = \", end=\"\")\n",
    "    for p, beta in enumerate(model.params):\n",
    "        print(\"{:.3f}\".format(beta), end=\"\")\n",
    "        if p > 0: \n",
    "            print(\" x^{} \".format(p), end=\"\")\n",
    "        else:\n",
    "            print(\" \", end=\"\")\n",
    "        if p != len(model.params)-1:\n",
    "            print(\"+ \", end=\"\")\n",
    "            \n",
    "    # Plot data/fit \n",
    "    yhat = model.predict(X)\n",
    "    res = y - yhat \n",
    "    xp = np.linspace(np.min(x), np.max(x), 50)\n",
    "    yp = np.zeros(len(xp))\n",
    "    for p, beta in enumerate(model.params):\n",
    "        yp += beta * xp**p \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16,6))\n",
    "    axes[0].scatter(x, y, color=\"steelblue\", s=100, alpha=0.9)\n",
    "    axes[0].plot(xp, yp, color=\"steelblue\", lw=3)\n",
    "    axes[0].grid(alpha=0.25)\n",
    "    axes[0].set_xlabel(\"X\", fontsize=16)\n",
    "    axes[0].set_ylabel(\"Y\", fontsize=16)\n",
    "    axes[0].set_title(\"Data and PLR Fit\", fontsize=16)\n",
    "    \n",
    "    # Plot residuals \n",
    "    axes[1].plot([np.min(x), np.max(x)], [0, 0], lw=2, ls=\"--\", alpha=0.5, color=\"black\")\n",
    "    axes[1].scatter(x, res, color=\"#6a9373\", s=100, alpha=0.9)\n",
    "    axes[1].grid(alpha=0.25)\n",
    "    axes[1].set_xlabel(\"X\", fontsize=16)\n",
    "    axes[1].set_ylabel(\"Res\", fontsize=16)\n",
    "    axes[1].set_title(\"Residual Plot\", fontsize=16)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
